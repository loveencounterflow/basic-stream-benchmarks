// Generated by CoffeeScript 1.11.1
(function() {
  var $as_line, $show, $split, CND, FS, PATH, badge, debug, format_float, format_integer, help, info, new_numeral, rpr, through2, warn;

  CND = require('cnd');

  rpr = CND.rpr;

  badge = 'BASIC-STREAM-BENCHMARKS';

  debug = CND.get_logger('debug', badge);

  warn = CND.get_logger('warn', badge);

  info = CND.get_logger('info', badge);

  help = CND.get_logger('help', badge);

  PATH = require('path');

  FS = require('fs');

  through2 = require('through2');

  $split = require('binary-split');

  new_numeral = require('numeral');

  format_float = function(x) {
    return (new_numeral(x)).format('0,0.000');
  };

  format_integer = function(x) {
    return (new_numeral(x)).format('0,0');
  };

  $show = function() {
    return through2(function(data, encoding, callback) {
      this.push(data);
      return callback();
    });
  };

  $as_line = function() {
    return through2(function(data, encoding, callback) {
      this.push(data + '\n');
      return callback();
    });
  };

  this.read_formula_data = function(handler) {
    var S, input, input_path, output, output_path;
    input_path = PATH.resolve(__dirname, '../test-data/Unicode-NamesList.txt');
    output_path = '/tmp/xxx.txt';
    input = FS.createReadStream(input_path);
    output = FS.createWriteStream(output_path);
    S = {};
    S.byte_count = 0;
    S.item_count = 0;
    S.t0 = null;
    S.t1 = null;
    input.pipe($split()).pipe(through2.obj(function(data, encoding, callback) {
      if (S.t0 == null) {
        S.t0 = Date.now();
      }
      S.byte_count += data.length;
      S.item_count += +1;
      this.push(data);
      return callback();
    })).pipe(through2.obj(function(data, encoding, callback) {
      this.push(data);
      return callback();
    })).pipe(through2.obj(function(data, encoding, callback) {
      this.push(data);
      return callback();
    })).pipe($as_line()).pipe(output);
    output.on('close', (function(_this) {
      return function() {
        S.t1 = Date.now();
        _this.report(S);
        return handler();
      };
    })(this));
    return null;
  };

  this.report = function(S) {
    var bps, bps_txt, byte_count_txt, dts, dts_txt, ips, ips_txt, item_count_txt;
    dts = (S.t1 - S.t0) / 1000;
    bps = S.byte_count / dts;
    ips = S.item_count / dts;
    byte_count_txt = format_integer(S.byte_count);
    item_count_txt = format_integer(S.item_count);
    dts_txt = format_float(dts);
    bps_txt = format_float(bps);
    ips_txt = format_float(ips);
    help(dts_txt + "s");
    help(byte_count_txt + " bytes / " + item_count_txt + " items");
    return help(bps_txt + " bps / " + ips_txt + " ips");
  };

  this.read_formula_data_basic_version = function(handler) {
    var byte_count, input, item_count, output, path, t0, t1;
    path = PATH.resolve(__dirname, '../../../mingkwai-rack/jizura-datasources/data/flat-files/shape/shape-breakdown-formula.txt');
    input = FS.createReadStream(path);
    output = FS.createWriteStream('/tmp/xxx.txt');
    byte_count = 0;
    item_count = 0;
    t0 = null;
    t1 = null;
    output.on('finish', (function(_this) {
      return function() {
        help("finished");
        return handler();
      };
    })(this));
    input.pipe($split()).pipe(through2.obj(function(data, encoding, callback) {
      this.push(data);
      return callback();
    })).pipe(through2.obj(function(data, encoding, callback) {
      this.push(data);
      return callback();
    })).pipe(through2.obj(function(data, encoding, callback) {
      this.push(data);
      return callback();
    })).pipe(output).pipe($('finish', (function(_this) {
      return function() {
        var bps, bps_txt, byte_count_txt, dts, dts_txt, ips, ips_txt, item_count_txt;
        t1 = Date.now();
        dts = (t1 - t0) / 1000;
        bps = byte_count / dts;
        ips = item_count / dts;
        byte_count_txt = format_integer(byte_count);
        item_count_txt = format_integer(item_count);
        dts_txt = format_float(dts);
        bps_txt = format_float(bps);
        ips_txt = format_float(ips);
        help(dts_txt + "s");
        help(byte_count_txt + " bytes / " + item_count_txt + " items");
        help(bps_txt + " bps / " + ips_txt + " ips");
        return handler();
      };
    })(this)));
    return null;
  };

  this.run_devtools_example = function() {
    var count, f;
    console.profile('build');
    count = 0;
    f = function() {
      urge("item #" + count);
      count += +1;
      if (count < 1000) {
        return setImmediate(function() {
          return f();
        });
      } else {
        return console.profileEnd('build');
      }
    };
    f();
    return setTimeout((function() {
      return f();
    }), 1e6);
  };

  this.test_1 = function() {
    return this.read_formula_data(function(error) {
      if (error != null) {
        throw error;
      }
      return help('ok');
    });
  };

  if (console.profile == null) {
    console.profile = function(name) {
      return warn('profile', name);
    };
  }

  if (console.profileEnd == null) {
    console.profileEnd = function(name) {
      return warn('profileEnd', name);
    };
  }

  if (module.parent == null) {
    this.test_1();
  }


  /*
  make plan to base future major version of PipeDreams directly on https://github.com/nodejs/readable-stream
  (and through2 etc)
  
  ways to solve current problem without rewriting PipeDreams:
  
  (1) try to read many sources in parallel
  (2) collect entire file content into single string / buffer; sizes are all OK for that
  (3) re-use existing pipeline for all files, only reset state
  
  use both approaches at the same time
   */

}).call(this);

//# sourceMappingURL=main.js.map
